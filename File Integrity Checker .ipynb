{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nazaninmahmoudy/notebook1f8f3c50e0?scriptVersionId=265070027\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# üîê File Integrity Checker","metadata":{}},{"cell_type":"markdown","source":"##### A tool in Python to monitor file changes, detect missing or modified files, create backups of altered files, generate CSV reports, and restore files to their original state. This is done by calculating the SHA-256 hash for each file to be monitored and saving these hashes in a JSON file as a baseline dataset. Each time a check is performed, the current SHA-256 hashes are computed and compared to the stored values to detect changes or missing files. In addition, it creates backups of altered files while preserving the directory structure, generates detailed CSV reports with timestamps and hash values, and can restore files to their original state from backups.\n\n","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport hashlib\nimport json\nimport shutil\nimport csv\nfrom datetime import datetime","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-01T12:57:49.016989Z","iopub.execute_input":"2025-10-01T12:57:49.017288Z","iopub.status.idle":"2025-10-01T12:57:49.026383Z","shell.execute_reply.started":"2025-10-01T12:57:49.017268Z","shell.execute_reply":"2025-10-01T12:57:49.025507Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def calculate_hash(file_path):\n    sha256 = hashlib.sha256()\n    with open(file_path, \"rb\") as f:\n        for chunk in iter(lambda: f.read(4096), b\"\"):\n            sha256.update(chunk)\n    return sha256.hexdigest()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T12:57:49.035532Z","iopub.execute_input":"2025-10-01T12:57:49.035886Z","iopub.status.idle":"2025-10-01T12:57:49.046572Z","shell.execute_reply.started":"2025-10-01T12:57:49.035861Z","shell.execute_reply":"2025-10-01T12:57:49.045699Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"A hash is a unique fixed-length string (like a digital fingerprint) generated from data. If the file changes even a bit, its hash will also change.\nThe function opens the file in binary mode, reads it chunk by chunk, feeds those chunks into a SHA-256 algorithm, and in the end spits out a unique hash string.","metadata":{}},{"cell_type":"code","source":"def build_database(directory, db_file=\"integrity_db.json\"):\n    db = {}\n    for root, _, files in os.walk(directory):\n        for file in files:\n            path = os.path.join(root, file)\n            db[path] = calculate_hash(path)\n    with open(db_file, \"w\") as f:\n        json.dump(db, f, indent=4)\n    print(f\"[+] Database created and saved to {db_file}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T12:57:49.061004Z","iopub.execute_input":"2025-10-01T12:57:49.061303Z","iopub.status.idle":"2025-10-01T12:57:49.067706Z","shell.execute_reply.started":"2025-10-01T12:57:49.061279Z","shell.execute_reply":"2025-10-01T12:57:49.066711Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"This function foes through all files in the given folder, calculates a hash for each one, and stores the results in a JSON file .  like creating a baseline database of our files so we can check later if anything changes.","metadata":{}},{"cell_type":"code","source":"def check_integrity(db_file=\"integrity_db.json\", backup_dir=None, report_csv=None):\n    if not os.path.exists(db_file):\n        print(\"[-] Database not found. Build database first.\")\n        return\n\n    with open(db_file, \"r\") as f:\n        db = json.load(f)\n\n    changes = []\n    for path, old_hash in db.items():\n        status = \"No Changes\"\n        new_hash = old_hash\n        if not os.path.exists(path):\n            status = \"MISSING\"\n        else:\n            new_hash = calculate_hash(path)\n            if new_hash != old_hash:\n                status = \"Changed\"\n                if backup_dir:\n                    rel_path = os.path.relpath(path, start=os.getcwd())\n                    backup_path = os.path.join(backup_dir, rel_path)\n                    os.makedirs(os.path.dirname(backup_path), exist_ok=True)\n                    shutil.copy2(path, backup_path)\n\n        changes.append({\n            \"file_path\": path,\n            \"status\": status,\n            \"old_hash\": old_hash,\n            \"new_hash\": new_hash,\n            \"checked_at\": datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        })\n        print(f\"[{status}] {path}\")\n\n    if report_csv:\n        report_csv = report_csv.strip() or None\n        if report_csv:\n            if os.path.isdir(report_csv):\n                report_csv = os.path.join(report_csv, \"report.csv\")\n            os.makedirs(os.path.dirname(report_csv), exist_ok=True)\n            with open(report_csv, \"w\", newline='', encoding='utf-8') as csvfile:\n                fieldnames = [\"file_path\", \"status\", \"old_hash\", \"new_hash\", \"checked_at\"]\n                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n                writer.writeheader()\n                for row in changes:\n                    writer.writerow(row)\n            print(f\"[+] Report saved to {report_csv}\")\n\ndef restore_files(backup_dir):\n    if not backup_dir or not os.path.exists(backup_dir):\n        print(\"[-] Backup directory not found.\")\n        return\n    for root, _, files in os.walk(backup_dir):\n        for file in files:\n            backup_file_path = os.path.join(root, file)\n            rel_path = os.path.relpath(backup_file_path, backup_dir)\n            original_path = rel_path\n            os.makedirs(os.path.dirname(original_path), exist_ok=True)\n            shutil.copy2(backup_file_path, original_path)\n            print(f\"[RESTORED] {original_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T12:57:49.117199Z","iopub.execute_input":"2025-10-01T12:57:49.117505Z","iopub.status.idle":"2025-10-01T12:57:49.129268Z","shell.execute_reply.started":"2025-10-01T12:57:49.11748Z","shell.execute_reply":"2025-10-01T12:57:49.128223Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"This function checks if the files saved in the database have changed or disappeared, optionally backs up any modified files, and can generate a CSV report listing all changes with timestamps.","metadata":{}},{"cell_type":"markdown","source":"If the database doesn‚Äôt exist, it prints an error and stops. Then it iterates through each file path stored in the database.\nFor each file, it sets a default status of \"No Changes\". If the file no longer exists on disk, the status is updated to \"MISSING\". If the file exists, the function calculates its current SHA-256 hash and compares it to the stored hash; if they differ, the status becomes \"Changed\".\n\nif a backup directory is provided, any modified files are copied to the backup folder while preserving the folder structure. All changes including file path, status, old and new hashes, and the timestamp of the check are recorded in a list. \nFinally, if a CSV path is given, the function writes this list to a CSV file. This provides a complete, timestamped snapshot of which files are unchanged, missing, or modified, and optionally stores backups for recovery.","metadata":{}},{"cell_type":"code","source":"def restore_files(backup_dir):\n    if not backup_dir or not os.path.exists(backup_dir):\n        print(\"[-] Backup directory not found.\")\n        return\n    for root, _, files in os.walk(backup_dir):\n        for file in files:\n            backup_file_path = os.path.join(root, file)\n            rel_path = os.path.relpath(backup_file_path, backup_dir)\n            original_path = rel_path\n            os.makedirs(os.path.dirname(original_path), exist_ok=True)\n            shutil.copy2(backup_file_path, original_path)\n            print(f\"[RESTORED] {original_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T12:57:49.142015Z","iopub.execute_input":"2025-10-01T12:57:49.142311Z","iopub.status.idle":"2025-10-01T12:57:49.154878Z","shell.execute_reply.started":"2025-10-01T12:57:49.142291Z","shell.execute_reply":"2025-10-01T12:57:49.153711Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"This code first checks whether the given backup_dir exists; if not, it prints an error and exits. Then, it walks through all files inside the backup folder recursively. For each file, it calculates its relative path with respect to the backup directory to preserve the folder structure. It creates any necessary parent directories at the original location and copies the file from the backup to its original path. After each file is restored, it prints a message indicating the restoration. This ensures that all backed-up files can be returned to their original locations.","metadata":{}},{"cell_type":"code","source":"def run_file_integrity_tool():\n    directory = input(\"Enter folder path\")\n\n    print(\"\\n1. Build database\")\n    print(\"2. Check integrity\")\n    print(\"3. Restore files\\n\")\n\n    choice = input(\"Select option (1/2/3): \")\n\n    if choice == \"1\":\n        if os.path.exists(directory):\n            build_database(directory)\n        else:\n            print(\"[-] Invalid folder path\")\n\n    elif choice == \"2\":\n        backup_dir = input(\"Enter backup folder path \").strip() or None\n        report_csv = input(\"Enter CSV report path \").strip() or None\n        check_integrity(\"integrity_db.json\", backup_dir, report_csv)\n\n    elif choice == \"3\":\n        backup_dir = input(\"Enter backup folder path to restore from: \").strip()\n        restore_files(backup_dir)\n\n    else:\n        print(\"[-] Invalid choice\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T12:57:49.174051Z","iopub.execute_input":"2025-10-01T12:57:49.174385Z","iopub.status.idle":"2025-10-01T12:57:49.181771Z","shell.execute_reply.started":"2025-10-01T12:57:49.17436Z","shell.execute_reply":"2025-10-01T12:57:49.180748Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"This block performs as the user interface.It prompts for a directory and a mode: \"Build database\", \"Check integrity\", or \"restore files\". \n\nIn build mode, it scans all files, calculates their SHA-256 hashes, and saves them in a JSON database as a baseline. In check mode, it recalculates hashes, compares them to the database, marks missing or changed files, optionally backs up modified files, and can generate a CSV report with timestamps.\n\nIn restore mode, it copies files from a backup directory back to their original locations. The code also handles invalid directories or modes, providing informative messages, effectively coordinating scanning, verification, backup, reporting, and restoration in a single workflow.","metadata":{}},{"cell_type":"code","source":"input_folder = \"/kaggle/input/information\"\n\nworking_folder = \"/kaggle/working/information\"\n\nshutil.copytree(input_folder, working_folder, dirs_exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T12:57:49.191409Z","iopub.execute_input":"2025-10-01T12:57:49.191772Z","iopub.status.idle":"2025-10-01T12:57:49.219958Z","shell.execute_reply.started":"2025-10-01T12:57:49.191744Z","shell.execute_reply":"2025-10-01T12:57:49.219078Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/information'"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"run_file_integrity_tool()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T12:57:49.221224Z","iopub.execute_input":"2025-10-01T12:57:49.221493Z","iopub.status.idle":"2025-10-01T12:58:04.227326Z","shell.execute_reply.started":"2025-10-01T12:57:49.221467Z","shell.execute_reply":"2025-10-01T12:58:04.22634Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter folder path /kaggle/working/information\n"},{"name":"stdout","text":"\n1. Build database\n2. Check integrity\n3. Restore files\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Select option (1/2/3):  1\n"},{"name":"stdout","text":"[+] Database created and saved to integrity_db.json\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"First , we created the dataset ","metadata":{}},{"cell_type":"code","source":"with open( \"/kaggle/working/information/ABC.txt\", \"a\", encoding=\"utf-8\") as f:\n    f.write(\"Some changes\\n\")  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T12:58:04.228803Z","iopub.execute_input":"2025-10-01T12:58:04.229305Z","iopub.status.idle":"2025-10-01T12:58:04.234513Z","shell.execute_reply.started":"2025-10-01T12:58:04.229279Z","shell.execute_reply":"2025-10-01T12:58:04.233409Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"Then , we made some changes in the file ","metadata":{}},{"cell_type":"code","source":"run_file_integrity_tool()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T12:58:04.235501Z","iopub.execute_input":"2025-10-01T12:58:04.235938Z","iopub.status.idle":"2025-10-01T12:59:06.291576Z","shell.execute_reply.started":"2025-10-01T12:58:04.235908Z","shell.execute_reply":"2025-10-01T12:59:06.290665Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter folder path /kaggle/working/information\n"},{"name":"stdout","text":"\n1. Build database\n2. Check integrity\n3. Restore files\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Select option (1/2/3):  2\nEnter backup folder path  /kaggle/working/backup\nEnter CSV report path  /kaggle/working/report\n"},{"name":"stdout","text":"[Changed] /kaggle/working/information/ABC.txt\n[+] Report saved to /kaggle/working/report\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"As we can see , the cange was detected .\nwe stored define a path to sotore the backup and cv report .","metadata":{}},{"cell_type":"code","source":"run_file_integrity_tool()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T12:59:06.293252Z","iopub.execute_input":"2025-10-01T12:59:06.293998Z","iopub.status.idle":"2025-10-01T12:59:34.358329Z","shell.execute_reply.started":"2025-10-01T12:59:06.293976Z","shell.execute_reply":"2025-10-01T12:59:34.357311Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter folder path /kaggle/working/information\n"},{"name":"stdout","text":"\n1. Build database\n2. Check integrity\n3. Restore files\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Select option (1/2/3):  3\nEnter backup folder path to restore from:  /kaggle/working/backup\n"},{"name":"stdout","text":"[RESTORED] information/ABC.txt\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"The original version at the time the database was created or at the moment the backup was made.","metadata":{}},{"cell_type":"markdown","source":"## Conclusion:\n\n\nThis tool reliably monitors file changes, detects modifications or missing files, creates backups, generates reports, and can restore files to their original state, helping maintain file integrity efficiently.","metadata":{}}]}